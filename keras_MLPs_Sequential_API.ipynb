{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#> python3 -m pip install --upgrade tensorflowhttp://localhost:8888/notebooks/Untitled.ipynb?kernel_name=python3#\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test,y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_full.shape)\n",
    "print(X_train_full.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. scale pixel density to 0-1, \n",
    "    2. carve out validation set, and trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000]/255.0, X_train_full[5000:]/255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    fashion_MNIST needs manual naming to target values naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=[\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Fluffy Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "       use Sequential API, build a neural network (2-layer MLP)\n",
    "       Sequential MLP is the simpliest form of ANN , that is a single stack of layers connectioned sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "\n",
    "keras.layers.Flatten(input_shape = [28,28]),\n",
    "keras.layers.Dense(300, activation = \"relu\"),\n",
    "keras.layers.Dense(100, activation = \"relu\"),\n",
    "keras.layers.Dense(10, activation = \"softmax\") #last layer spit out 10 classes\n",
    "    \n",
    "])\n",
    "print(model.layers)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "       Note: 266,610 = 300 (nodes) x 784 (features) + 300 (bias terms, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access layers and Weights/Bias\n",
    "\n",
    "hidden_l1 = model.layers[1]\n",
    "w1, b1 = hidden_l1.get_weights()\n",
    "print(w1.shape)\n",
    "print(b1.shape)\n",
    "print(w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initial weights are random, initial bias are 0s, \n",
    "to change this, use kernel_initializer ,bias_initializer via https://keras.io/initializers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________\n",
    "\n",
    "Use compile() to set loss_function, optimizer/learning_algo, and accuracy metrics<BR>\n",
    "when using SGD (Stochastic Gradient Decsent, tuning learning rate is critical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss= \"sparse_categorical_crossentropy\", \n",
    "    optimizer=keras.optimizers.SGD(lr = 0.01), \n",
    "    metrics = [\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs = 30, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierarchy of fine-tuning your hyperparameters\n",
    "1. learning rate\n",
    "2. optimizer (and then learning rate)\n",
    "3. number of layers, \n",
    "4. number of nerous per layers\n",
    "5. batch size\n",
    "\n",
    "Once validation/accuracy is good enough on the validation set\n",
    "\n",
    "evaulate the fitted model on test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
